{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nu05OnVwtU5x",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import glob \n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image as im\n",
    "from model import Gauss2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lT4o7KButU50"
   },
   "outputs": [],
   "source": [
    "show        = True \n",
    "pretrain    = False\n",
    "data_dir    = 'data'\n",
    "filename    = 'model_out_gauss.pth'\n",
    "batch_size  = 20       #Number of samples in each batch\n",
    "num_workers = 4\n",
    "epoch_num   = 5        #Number of epochs to train the network\n",
    "lr          = 0.01     # Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jkO-nOimtU50",
    "outputId": "f1a91fe2-b860-4788-e035-e317619583df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.ToTensor(),\n",
    "    'val': transforms.ToTensor()\n",
    "}\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=num_workers)\n",
    "               for x in ['train', 'val']}\n",
    "print(len(dataloaders['train']))\n",
    "print(len(dataloaders['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YlIw51UGtU51",
    "outputId": "610a657d-6e76-434f-b68c-a28d6321bfa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EAAzz5yftU52",
    "outputId": "cc87f0da-b61e-449e-c5a7-c09c20f6a534"
   },
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "#Gauss2D.imshow(out,title=[class_names[x] for x in classes], fname='initial.jpg',show=False)\n",
    "\n",
    "\n",
    "model_ft = models.resnet18(pretrained=pretrain)\n",
    "if torch.cuda.device_count() > 1: \n",
    "    print(\"Using \", torch.cuda.device_count(),\"gpus!\")\n",
    "    model_ft = nn.DataParallel(model_ft) #\n",
    "    \n",
    "model_ft=model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fIA3ZjzotU52",
    "outputId": "8e71c276-eeb3-4a70-fa75-5478e5af2dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.3008 Acc: 0.9256\n",
      "val Loss: 0.1055 Acc: 0.9548\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.1622 Acc: 0.9542\n",
      "val Loss: 0.1079 Acc: 0.9724\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.1325 Acc: 0.9539\n",
      "val Loss: 0.0811 Acc: 0.9673\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.1139 Acc: 0.9575\n",
      "val Loss: 0.0886 Acc: 0.9673\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.1101 Acc: 0.9619\n",
      "val Loss: 0.0534 Acc: 0.9749\n",
      "\n",
      "Training complete in 3m 17s\n",
      "Best val Acc: 0.974874\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "model_ft = Gauss2D.train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=epoch_num, dataloaders=dataloaders, device=device,dataset_sizes=dataset_sizes)\n",
    "torch.save(model_ft, filename)\n",
    "\n",
    "#Gauss2D.visualize_model(model_ft,num_images=4,device=device,dataloaders=dataloaders,class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "ZYiQrpMPgxxq",
    "outputId": "45fea992-0ae5-440a-ec72-466ee5689736"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-913b90bc4d90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnb_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns \n",
    "import pandas as pd \n",
    "\n",
    "nb_classes = 2\n",
    "\n",
    "# Initialize the prediction and label lists(tensors)\n",
    "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(dataloaders['val']):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model_ft(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Append batch prediction results\n",
    "        predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
    "        lbllist=torch.cat([lbllist,classes.view(-1).cpu()])\n",
    "\n",
    "# Confusion matrix\n",
    "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
    "print(conf_mat)\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
    "print(class_accuracy)\n",
    "labels = ['one','two']\n",
    "ax= plt.subplot()\n",
    "\n",
    "\n",
    "sns.heatmap(conf_mat, annot=True)\n",
    "class_names = np.asarray(labels)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_xticklabels(class_names.flatten())\n",
    "ax.set_yticklabels(class_names.flatten())\n",
    "ax.set_title('Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
