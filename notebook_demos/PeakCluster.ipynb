{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import math\n",
    "import matplotlib \n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabasz_score \n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir        = '../patches'\n",
    "num_workers     = 4\n",
    "crop_size       = 8\n",
    "data_transforms = transforms.Compose([transforms.CenterCrop(crop_size),\n",
    "                                      transforms.Grayscale(),\n",
    "                                      transforms.ToTensor()])\n",
    "device          = torch.device(\"cpu\")#cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset   = datasets.ImageFolder(os.path.join(data_dir),data_transforms)\n",
    "dataloader      = torch.utils.data.DataLoader(image_dataset,num_workers=num_workers,batch_size=len(image_dataset))\n",
    "images,labels   = next(iter(dataloader))\n",
    "print(len(image_dataset))\n",
    "images = images.to(device, torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(len(images),-1)\n",
    "images = images.cpu().numpy() \n",
    "#images = StandardScaler().fit_transform(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters=range(2,20) \n",
    "\n",
    "summed_square_distance=[]\n",
    "calinski_score=[]\n",
    "\n",
    "for i in clusters: \n",
    "    kmeans=KMeans(n_clusters=i,init='random',random_state=1)\n",
    "    kmeans=kmeans.fit(images)\n",
    "    summed_square_distance.append(kmeans.inertia_)\n",
    "    calinski_score.append(calinski_harabasz_score(images,kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd derivative of elbow curve to find optimal number of clusters \n",
    "spline    = UnivariateSpline(clusters,summed_square_distance)\n",
    "spline_d2 = spline.derivative(n=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_list = list(spline_d2(clusters))\n",
    "idx_max = max(range(len(d2_list)),key=d2_list.__getitem__)\n",
    "print(range(len(d2_list)))\n",
    "n_clusters=idx_max + min(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure() \n",
    "plt.plot(clusters,spline_d2(clusters))\n",
    "yint = range(min(clusters), math.ceil(max(clusters)))\n",
    "plt.xticks(yint)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_clusters)\n",
    "model = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "model.fit(images)\n",
    "Y = model.labels_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA to 2D \n",
    "pca           = PCA(n_components=2)\n",
    "pca_transform = pca.fit_transform(images)\n",
    "\n",
    "plt.figure()\n",
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    "i=0\n",
    "pca_holder = pd.DataFrame(columns=['pca0','pca1','label'])\n",
    "pca_holder['pca0']   = pca_transform[:,0]\n",
    "pca_holder['pca1']   = pca_transform[:,1]\n",
    "pca_holder['labels'] = Y \n",
    "unique_labels = set(pca_holder['labels']) \n",
    "plt.scatter(pca_transform[:,0],pca_transform[:,1], c=Y,cmap=plt.cm.jet)\n",
    "plt.tight_layout() \n",
    "plt.savefig('pca_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_cluster_labels(kmeans, actual_labels):\n",
    "    inferred_labels = {}\n",
    "    for i in range(kmeans.n_clusters):\n",
    "\n",
    "        # find index of points in cluster\n",
    "        labels = []\n",
    "        index = np.where(kmeans.labels_ == i)\n",
    "\n",
    "        # append actual labels for each point in cluster\n",
    "        labels.append(actual_labels[index])\n",
    "\n",
    "        # determine most common label\n",
    "        if len(labels[0]) == 1:\n",
    "            counts = np.bincount(labels[0])\n",
    "        else:\n",
    "            counts = np.bincount(np.squeeze(labels))\n",
    "        #print(counts)    \n",
    "        # assign the cluster to a value in the inferred_labels dictionary\n",
    "        if np.argmax(counts) in inferred_labels:\n",
    "            # append the new number to the existing array at this slot\n",
    "            inferred_labels[np.argmax(counts)].append(i)\n",
    "        else:\n",
    "            # create a new array in this slot\n",
    "            inferred_labels[np.argmax(counts)] = [i]\n",
    "\n",
    "        #print(labels)\n",
    "        #print('Cluster: {}, label: {}'.format(i, np.argmax(counts)))\n",
    "    \n",
    "    return inferred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = model.cluster_centers_\n",
    "images = centroids.reshape(n_clusters, crop_size, crop_size)\n",
    "images *= 255\n",
    "images = images.astype(np.uint8)\n",
    "\n",
    "\n",
    "# determine cluster labels\n",
    "cluster_labels = infer_cluster_labels(model, Y)\n",
    "\n",
    "\n",
    "\n",
    "# create figure with subplots using matplotlib.pyplot\n",
    "fig, axs = plt.subplots(int(n_clusters/2), 2, figsize = (20, 20))\n",
    "plt.gray()\n",
    "\n",
    "# loop through subplots and add centroid images\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    \n",
    "    # determine inferred label using cluster_labels dictionary\n",
    "    for key, value in cluster_labels.items():\n",
    "        if i in value:\n",
    "            ax.set_title('Inferred Label: {}'.format(key))\n",
    "    \n",
    "    # add image to subplot\n",
    "    ax.matshow(images[i])\n",
    "    ax.axis('off')\n",
    "    \n",
    "# display the figure\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
