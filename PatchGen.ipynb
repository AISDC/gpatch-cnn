{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, models, transforms, utils\n",
    "from cc_torch import connected_components_labeling\n",
    "import numpy as np\n",
    "import torch\n",
    "import os \n",
    "import time \n",
    "\n",
    "from skimage.measure import label, regionprops\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage.color import label2rgb\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_patch(image, label, idx, area_cutoff):\n",
    "    masks=[]\n",
    "    bbox=[]\n",
    "    for region in regionprops(label):\n",
    "        if region.area > area_cutoff: \n",
    "            masks.append(region.filled_image)\n",
    "            bbox.append(region.bbox) \n",
    "\n",
    "    j=0\n",
    "    if os.path.exists('patches') is False: \n",
    "        os.mkdir('patches')\n",
    "    if os.path.exists('patches/img_%i' %idx) is False: \n",
    "        os.mkdir('patches/img_%i' %idx)\n",
    "    for box, mask in zip(bbox,masks):\n",
    "        im = Image.fromarray(mask)\n",
    "        im.save('patches/img_%i/img_%i_patch_%i.png' %(idx,idx,j))\n",
    "        j+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir        = 'data_diffract'\n",
    "num_workers     = 4\n",
    "data_transforms = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                            transforms.ToTensor()])\n",
    "device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: \n",
    "    print(\"Using\", torch.cuda.device_count(),\"gpus!\")\n",
    "\n",
    "image_dataset   = datasets.ImageFolder(os.path.join(data_dir),data_transforms)\n",
    "\n",
    "dataloader      = torch.utils.data.DataLoader(image_dataset,num_workers=num_workers,batch_size=len(image_dataset))\n",
    "images,labels   = next(iter(dataloader))\n",
    "\n",
    "images = images.to(device, torch.uint8)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "for image in images:\n",
    "    image = torch.reshape(image,(2048,2048))\n",
    "    cc_out = connected_components_labeling(image)\n",
    "    cc_out = cc_out.cpu().numpy()\n",
    "    image  = image.cpu().numpy() \n",
    "    cc_image_overlay = label2rgb(cc_out,image=image,bg_label=0)\n",
    "    write_patch(cc_image_overlay,cc_out,idx,area_cutoff=1)\n",
    "    idx+=1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
